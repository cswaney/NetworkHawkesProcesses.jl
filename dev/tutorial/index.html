<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Tutorial · NetworkHawkesProcesses.jl</title><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../"><img src="../assets/logo.png" alt="NetworkHawkesProcesses.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../">NetworkHawkesProcesses.jl</a></span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li class="is-active"><a class="tocitem" href>Tutorial</a><ul class="internal"><li><a class="tocitem" href="#Mathematical-Background"><span>Mathematical Background</span></a></li><li><a class="tocitem" href="#Continuous-Processes"><span>Continuous Processes</span></a></li><li><a class="tocitem" href="#Discrete-Processes"><span>Discrete Processes</span></a></li></ul></li><li><a class="tocitem" href="../examples/">Examples</a></li><li><a class="tocitem" href="../api/">API</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Tutorial</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Tutorial</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/cswaney/NetworkHawkesProcesses.jl/blob/master/docs/src/tutorial.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h2 id="Mathematical-Background"><a class="docs-heading-anchor" href="#Mathematical-Background">Mathematical Background</a><a id="Mathematical-Background-1"></a><a class="docs-heading-anchor-permalink" href="#Mathematical-Background" title="Permalink"></a></h2><p>Hawkes processes are a class of inhomogeneous, autoregressive Poisson processes used to model the arrival of events that demonstrate self-exciting behavior, e.g., seismic activity. The intensity of a univariate Hawkes process given a sequence of events <span>$\{ s_i \}_{i=1}^N$</span> is given by the expression</p><p class="math-container">\[\lambda(t) = \lambda^{(0)}(t) + \sum_{s_i &lt; t} h(t - s_i \ | \ \theta),\]</p><p>where <span>$\lambda^{(0)}$</span> is the (possibly inhomogenous) baseline intensity of the process in the absence of events, and <span>$h(\Delta t)$</span> is a non-negative impulse response that captures the increase in intensity due to each event. Simply put, every event arrival temporarily increases the likelihood of future events.</p><p>Multivariate Hawkes processes introduce the possibility of interactions between processes. The intensity of the <span>$n$</span>-th process given a sequence of events <span>$\{ s_i \}_{i=1}^N$</span> occurring on corresponding processes <span>$\{ c_i \}_{i=1}^N$</span> is given by</p><p class="math-container">\[\lambda_n(t) = \lambda_n^{(0)}(t) + \sum_m \sum_{\substack{c_i = m,\\ s_i &lt; t}} h_{m \rightarrow n}(t - s_i \ | \ \theta_{m \rightarrow n}),\]</p><p>where the impulse response <span>$h(\Delta t \ | \ \theta_{m \rightarrow n})$</span> now depends on the &quot;parent&quot; process, <span>$m$</span>, and &quot;child&quot; process, <span>$n$</span>.</p><p><code>NetworkHawkesProcess.jl</code> implements a class of probabilistic models that combines multivariate Hawkes processes with network models (<a href="https://dash.harvard.edu/handle/1/33493391">Linderman, 2016</a>). The intensity of such models takes the form</p><p class="math-container">\[\lambda_n(t) = \lambda_n^{(0)}(t) + \sum_m \sum_{\substack{c_i = m,\\ s_i &lt; t}} a_{m \rightarrow n} h_{m \rightarrow n}(t - s_i \ | \ \theta_{m \rightarrow n}),\]</p><p>where <span>$a_{m \rightarrow n}$</span> is a binary variable representing the existence of a directed link from process <span>$m$</span> to process <span>$n$</span> generated by a process</p><p class="math-container">\[a_{m \rightarrow n} \sim p(a_{m \rightarrow n} \ | \ \eta_{m \rightarrow n})\]</p><p>These models–network Hawkes processes–permit simultaneous inference on the structure of a network and its event generating process. The following sections demonstrate how to use this package to construct, simulate, and perform inference on such processes.</p><h2 id="Continuous-Processes"><a class="docs-heading-anchor" href="#Continuous-Processes">Continuous Processes</a><a id="Continuous-Processes-1"></a><a class="docs-heading-anchor-permalink" href="#Continuous-Processes" title="Permalink"></a></h2><p>This section explores the continuous-time network Hawkes process. We&#39;ll examine the component parts of the process, generate simulated data, and learn how inference works. </p><p>Let&#39;s start by reviewing the multivariate, continuous-time network Hawkes process. The process consists of <span>$n$</span> Poisson processes, with the intensity of its <span>$n$</span>-th node taking the form</p><p class="math-container">\[\lambda_n(t \ | \ \{s_m, c_m \}) = \lambda_n^{(0)}(t) + \sum_{s_m &lt; t} a_{c_m \rightarrow n} \cdot w_{c_m \rightarrow n} \cdot \hbar(\Delta t; \theta_{c_m \rightarrow n})\]</p><ul><li><p><span>$\lambda_n^{(0)}$</span> is the <em>baseline</em> intensity of the process, which represents the intensity of the process in the abscence of events.</p></li><li><p><span>$a_{c_m \rightarrow n}$</span> is the <span>$(c_m, n)$</span>-th component of the binary <em>adjacency matrix</em>, <span>$\mathbf{A}$</span>. The components of <span>$\mathbf{A}$</span> determine whether connections exists between nodes in the network. If no connection exists between nodes <span>$i$</span> and <span>$j$</span>, then events on node <span>$i$</span> have no effect on the intensity of node <span>$j$</span>. The model assumes that <span>$\mathbf{A}$</span> is generated by a <em>network model</em>, as described below.</p></li><li><p><span>$w_{c_m \rightarrow n}$</span> is the <span>$(c_m, n)$</span>-th component of the <em>weight matrix</em>, <span>$\mathbf{W}$</span>. Whereas <span>$a_{i, j}$</span> determines the existence of a connection from node <span>$i$</span> to node <span>$j$</span>, <span>$w_{i, j}$</span> determines the connection&#39;s <em>strength</em>.</p></li></ul><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>In generally, the weight matrix can also be modeled as the result of a network-type model, but this option is not currently supported.</p></div></div><ul><li><span>$\hbar(\Delta t ; \theta_{c_m \rightarrow n})$</span> is a non-negative <em>impulse response</em> function, which controls the evolution of the <span>$n$</span>-th node&#39;s response to events on node <span>$c_m$</span>. Its shape is determined by connection-specific parameters <span>$\theta_{c_m \rightarrow n}$</span>. </li></ul><p>In summary, the continuous-time network Hawkes process is a network of interacting Poisson processes, which consists of: a baseline, an adjacency matrix, a weight matrix, and an impulse response function. Now let&#39;s create some of these processes in <code>NetworkHawkesProcesses</code> to see how this all works.</p><h3 id="Standard-Hawkes-Processes"><a class="docs-heading-anchor" href="#Standard-Hawkes-Processes">Standard Hawkes Processes</a><a id="Standard-Hawkes-Processes-1"></a><a class="docs-heading-anchor-permalink" href="#Standard-Hawkes-Processes" title="Permalink"></a></h3><p><code>NetworkHawkesProcesses</code> allows users to contruct models with network structure, but let&#39;s start by considering a simpler, &quot;standard&quot; Hawkes model, which we construct as follows:</p><pre><code class="language-julia hljs">nnodes = 2;
baseline = HomogeneousProcess(rand(nnodes));
impulses = ExponentialImpulseResponse(rand(nnodes, nnodes));
weights = DenseWeightModel(rand(nnodes, nnodes));
process = ContinuousStandardHawkesProcess(baseline, impulses, weights);</code></pre><p>The process is straight-forward: define the component parts, then define the process. But let&#39;s take a look at the component parts to understand what we&#39;ve just created.</p><h4 id="Baseline"><a class="docs-heading-anchor" href="#Baseline">Baseline</a><a id="Baseline-1"></a><a class="docs-heading-anchor-permalink" href="#Baseline" title="Permalink"></a></h4><p>First, we need to define a baseline intensity. The simplest choice is a homogeneous Poisson process:</p><p class="math-container">\[\lambda_n^{(0)}(t) = \lambda_n^{(0)}\]</p><p>We can create this process using <code>HomogeneousProcess</code>:</p><pre><code class="language-julia hljs">nnodes = 2;
baseline = HomogeneousProcess(rand(nnodes))</code></pre><p>However, a constant baseline intensity is unrealistic in many applications. The package also provides a flexible alternative, the <code>LogGaussianCoxProcess</code>. This process uses <a href="https://en.wikipedia.org/wiki/Gaussian_process">Gaussian processes</a> to capture time-varying intensity, which is particularly useful when modeling processes with (e.g.) known periodic properties. We&#39;ll consider the <code>LogGaussianCoxProcess</code> more closely later.</p><h4 id="Weights"><a class="docs-heading-anchor" href="#Weights">Weights</a><a id="Weights-1"></a><a class="docs-heading-anchor-permalink" href="#Weights" title="Permalink"></a></h4><p>Next, we need to define our weight model. In general, a weight model can be any network model that generates a non-negative weight matrix. Currently, the package only provides a simple weight model that represents weights as a constant matrix:</p><pre><code class="language-julia hljs">weights = DenseWeightModel(rand(nnodes, nnodes))</code></pre><h4 id="Impulse-Response"><a class="docs-heading-anchor" href="#Impulse-Response">Impulse Response</a><a id="Impulse-Response-1"></a><a class="docs-heading-anchor-permalink" href="#Impulse-Response" title="Permalink"></a></h4><p>Finally, we need to define an impulse response. Constraining <span>$\hbar$</span> to be a valid probability density ensures that it <em>only</em> determines the timing of responses because each impulse response integrates to one, and therefore contributes identically to the likelihood of events. Additionally, each <span>$w_{n&#39; \rightarrow n}$</span> becomes the <em>expected</em> number of events on node <span>$n$</span> resulting directly from a single event on node <span>$n&#39;$</span>. In other words, we can meaningfully compare weights.</p><p>Let&#39;s start with a classic choice, the exponential distribution:</p><p class="math-container">\[\hbar(\Delta t; \theta_{n&#39; \rightarrow n}) = \theta_{n&#39; \rightarrow n} \exp \{-\theta_{n&#39; \rightarrow n} \cdot \Delta t \}\]</p><p><img src="../assets/img/exponential-impulse-response.svg" alt="Exponential Impulse Response"/></p><p>We create this model with the <code>ExponentialImpulseResponse</code> struct:</p><pre><code class="language-julia hljs">impulses = ExponentialImpulseResponse(rand(nnodes, nnodes))</code></pre><p>In addition to specifying the actual impulse response function, this model defines data and logic used for inference. We&#39;ll skip these details for now.</p><h4 id="Stability"><a class="docs-heading-anchor" href="#Stability">Stability</a><a id="Stability-1"></a><a class="docs-heading-anchor-permalink" href="#Stability" title="Permalink"></a></h4><p>Before we move on, we should note that we have assigned random values to our model parameters. While these values are valid for the component models, they may lead to an <em>unstable</em> process, i.e., whose intensity eventually &quot;blows up&quot;. Let&#39;s check if our process is stable:</p><pre><code class="language-julia hljs">isstable(process)</code></pre><p>This function simply checks the stability condition:</p><p class="math-container">\[\max_{| \lambda |} \text{eig} \left( \mathbf{A} \odot \mathbf{W} \right) &lt; 1.0\]</p><h4 id="Simulation"><a class="docs-heading-anchor" href="#Simulation">Simulation</a><a id="Simulation-1"></a><a class="docs-heading-anchor-permalink" href="#Simulation" title="Permalink"></a></h4><p>Next, let&#39;s examine what data generated by this process looks like. Following Julia convention, random data is generated using the <code>rand</code> method. For example, here&#39;s how to simulate data for a period of length <code>T=10.0</code>:</p><pre><code class="language-julia hljs">events, nodes, duration = rand(process, 1000.0)
println(&quot;(process generated $(length(events)) events)&quot;)</code></pre><p>Notice that the output of a continuous process has three parts: a list of event times (<code>events</code>), followed by a list of corresponding event nodes, and the duration of the simulation. The reason we return <code>duration</code> is that it is required for continuous-time inference methods. Returning it means that we run inference directly on the output of <code>rand</code>, i.e., without unpacking as above.</p><p>Let&#39;s take a look at our data:</p><pre><code class="language-julia hljs">data = (events, nodes, duration)
plot(processs, data)</code></pre><p><img src="../assets/img/exponential-intensity.svg" alt="Intensity"/></p><p>Each point of the plot represents an event, and the curves represent the intensity of the nodes. The exponential impulse reponse function produces an instantaneous increase in intensity after each event, which is followed by a gradual decline. This puncuated behavior is undesirable or unrealistic in many applications. For that reason, <code>NetworkHawkesProcesses</code> provides a more flexible impulse resopnse function based on the logit-normal distribution:</p><p class="math-container">\[\hbar(\Delta t; \mu_{n&#39; \rightarrow n}, \tau_{n&#39; \rightarrow n}) = \frac{1}{Z} \exp \Bigg \{ \frac{-\tau_{n&#39; \rightarrow n}}{2} \left( \sigma^{-1} \left( \frac{\Delta t}{\Delta t_{\text{max}}} \right) \right) \Bigg \}\]</p><p><span>$\hbar$</span> is again a proper probability distribution on <span>$[0, \Delta t_{\text{max}}]$</span>, where <span>$\Delta t_{\text{max}}$</span> is a hyperparameter (i.e., not learned through inference). The distribution provides flexibility in the timing of the impulse response at the cost of a second parameter, <span>$\mathbf{\tau}$</span>, as demonstrated in the figure below.</p><p><img src="../assets/img/logit-normal-impulse-response.svg" alt="Logit-Normal Impulse Response"/></p><p><code>LogitNormalImpulseResponse</code> implements this impulse reponse function along with all methods required to perform statistical inference. Let&#39;s update our process to use this impulse response and generate a new sample:</p><pre><code class="language-julia hljs">Δtmax = 1.0;
impulses = LogitNormalImpulseResponse(rand(nnodes, nnodes), rand(nnodes, nnodes), Δtmax);
process = ContinuousStandardHawkesProcess(baseline, impulses, weights);
events, nodes, duration = data = rand(process, duration);
println(&quot;(process generated $(length(events)) events)&quot;)</code></pre><p>As demostrated in the following figure, the response to events is now noticably delayed:</p><p><img src="../assets/img/logit-normal-intensity.svg" alt="Logit-Normal Impulse Response"/></p><h4 id="Inference"><a class="docs-heading-anchor" href="#Inference">Inference</a><a id="Inference-1"></a><a class="docs-heading-anchor-permalink" href="#Inference" title="Permalink"></a></h4><p>Typically, our interest is in learning the parameters of a model given data collected from an experiment or real-world dataset. <code>ContinuousStandardHawkesProcess</code> is compatible with maximum-likelihood estimation (<code>mle!</code>) and Markov chain Monte Carlo (Gibbs) sampling (<code>mcmc!</code>) methods:</p><pre><code class="language-julia hljs">using NetworkHawkesProcesses: params
orginial_process = deepcopy(process)
mle!(process, data; verbose=true, regularize=true); # regularize w/ prior
[params(process) params(original_process)]</code></pre><p>Note that inference methods in <code>NetworkHawkesProcesses</code> are mutating operations. That is, they update the parameters of the process they are called on. In this case, we saved a copy of the original process for comparison with our inference results, but we wouldn&#39;t normally need to make a copy. Notice as well that we did not initialize these methods. Behind the scenes, <code>mle!</code> and <code>mcmc!</code> created default, random initial guesses of the model parameters. You can override the default value by providing a <code>guess</code> parameter. For example, we could use the results of maximum-likelihood estimation as initial parameter values for Gibbs sampling.</p><h3 id="Networks"><a class="docs-heading-anchor" href="#Networks">Networks</a><a id="Networks-1"></a><a class="docs-heading-anchor-permalink" href="#Networks" title="Permalink"></a></h3><p>At this point, our model allows us to infer the strength of connections between nodes, but not whether such connections actually exist. A simple approach to predicting connections is to apply a hard threshold to estimates of <span>$\mathbf{W}$</span>, i.e., <span>$\hat{w}_{m \rightarrow n} \leftarrow \min \left( \hat{w}_{m \rightarrow n} - w_{\text{min}}, 0 \right)$</span>. The network Hawkes model provides a more disciplined approach by specifying a generative model for network connections.</p><p>In general, a network model takes the form</p><p class="math-container">\[p(\mathbf{A} \ | \ \mathbf{z}, \mathbf{\nu}) = \prod_{n=1}^N \prod_{n&#39;=1}^N p(a_{n \rightarrow n&#39;} \ | \ z_n, z_{n&#39;}, \mathbf{\nu}) = \prod_{n=1}^N \prod_{n&#39;=1}^N \text{Bern}(a_{n \rightarrow n&#39;} \ | \ \rho_{n \rightarrow n&#39;})\]</p><p>where <span>$\rho_{n \rightarrow n&#39;} = f(a_n, z_n, z_{n&#39;}, \nu)$</span>. In the probabilistic modeling lingo, <span>$z_i$</span> are referred to as &quot;local&quot; parameters and <span>$\nu$</span> is called a &quot;global&quot; parameter. <code>NetworkHawkesProcesses</code> has one such model built-in, the so-called Bernoulli network,</p><p class="math-container">\[p \left( a_{n \rightarrow n&#39;} \right) = \text{Bern} \left( a_{n \rightarrow n&#39;} \ | \ \rho \right),\]</p><p>which is implemented by the <code>BernoulliNetworkModel</code> struct. Constructing a continuous-time Hawkes process with this network model imposed on interactions is straight-forward:</p><pre><code class="language-julia hljs">baseline = HomogeneousProcess([1.0, 2.0]);
weights = DenseWeightModel([0.1 0.2; 0.2 0.1]);
impulses = LogitNormalImpulseResponse(ones(nnodes, nnodes), ones(nnodes, nnodes), Δtmax);
network = BernoulliNetworkModel(0.5, nnodes);
links = [1 0; 1 1];
process = ContinuousNetworkHawkesProcess(baseline, impulses, weights, links, network);</code></pre><p>The steps are similar to those used to create a standard Hawkes process. We pass the baseline, weights, and impulse response models to <code>ContinuousNetworkHawkesProcess</code> as before, but we now also include the network model and binary connection matrix, <code>links</code>, which takes the same form as a realization of network model (we could have also done <code>links = rand(network)</code>).</p><p>Simulating data works exactly as before:</p><pre><code class="language-julia hljs">data = rand(process, duration);</code></pre><p>Maximum-likelihood estimation isn&#39;t permitted for network Hawkes processes due to the binary adjacency matrix. However, we can still perform Gibbs sampling:</p><pre><code class="language-julia hljs">res = mcmc!(process, data; verbose=true);</code></pre><p>By default, <code>mcmc!</code> resamples the process parameters <code>nsteps=1000</code> times, and the samples are stored in <code>res.samples</code>. For example, we can get point estimates of model parameters by taking statistics of the samples:</p><pre><code class="language-julia hljs">using Statistics
mean(res.samples)</code></pre><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>Taking the median sample is the more typical choice, but <code>median</code> doesn&#39;t work on vectors, unfortunately. Instead, we can take medians of individual elements with <code>median([x[1] for x in res.samples])</code>.</p></div></div><h2 id="Discrete-Processes"><a class="docs-heading-anchor" href="#Discrete-Processes">Discrete Processes</a><a id="Discrete-Processes-1"></a><a class="docs-heading-anchor-permalink" href="#Discrete-Processes" title="Permalink"></a></h2><p>Discrete-time processes are similar to their continuous-time counterparts in most respects. Essentially, model components are discretized in the time dimension, where applicable. This means that baselines become discrete-time Poisson processes and impulse responses are translated to discrete distributions, but there is <em>no change</em> to network models or weights.</p><p>What might we want to use a discrete-time model? The primary motivation for discrete-time processes is faster inference. When events occur frequently, discrete-time processes offer faster inference because several events fall into the same time bin. Thus, discrete-time inference scales linearly with number of <em>time bins</em>. In contrast, continuous-time models scale quadratically with the number of events (although this is mollified by introduction of maximal look-back periods)<sup class="footnote-reference"><a id="citeref-1" href="#footnote-1">[1]</a></sup>. In addition, the discrete-time model permits variational inference, which leads to further computational gains (at the cost of simlifying dependence structures). Furthermore, in many cases we may only have access to discrete data, which necessicates a discrete-time model.</p><p>Here&#39;s how we would implement the previous example using a discrete-time model instead:</p><pre><code class="language-julia hljs">nnodes = 2;
nbasis = 3;
nlags = 4;
duration = 1000;
dt = 1.0;
baseline = DiscreteHomogeneousProcess([1.0, 2.0], dt);
weights = DenseWeightModel([0.1 0.2; 0.2 0.1]);
impulses = DiscreteGaussianImpulseResponse(ones(nnodes, nnodes, nbasis) ./ nbasis, nlags, dt);
process = DiscreteStandardHawkesProcess(baseline, impulses, weights, dt);
data = rand(process, duration);
res = mle!(process, data; verbose=true, regularize=false); # or mcmc!, vb!
ll = loglikelihood(process, data)</code></pre><p>There are several important differences to take note of. First, we now need to choose a time step size for the process, <code>dt</code>, which is also provided to all components that involve time (i.e., the baseline, impulse-response). Second, we use a discrete-time baseline process, <code>DiscreteHomogeneousProcess</code>, which is an exact discretized analog of <code>HomogeneousProcess</code>. <code>NetworkHawkesProcesses</code> also provides a discrete-time version of the non-homogeneous log Gaussian Cox process,  <code>DiscreteLogGaussianCoxProcess</code>. Third, we instantiate a discrete-time impulse response, <code>DiscreteGaussianImpulseResponse</code>, which has no continuous-time analog and is explained in detail below. Finally, <code>data</code> is now a <code>Matrix{Int64}</code> of size <code>nnodes x duration</code> containing event counts for each node along its rows. (Unlike the continuous-time model, we don&#39;t need to return nodes, events, and duration separately because they are implied by the data matrix dimensions).</p><p><img src="../assets/img/discrete-data.svg" alt="Discrete-time Data"/></p><h3 id="Discrete-time-Impulse-Responses"><a class="docs-heading-anchor" href="#Discrete-time-Impulse-Responses">Discrete-time Impulse Responses</a><a id="Discrete-time-Impulse-Responses-1"></a><a class="docs-heading-anchor-permalink" href="#Discrete-time-Impulse-Responses" title="Permalink"></a></h3><p>Whereas continuous-time impulse responses are typically determined by probability density functions, discrete-time impulse responses are specified by probability <em>mass</em> functions (i.e., points on a simplex). The approach of <code>NetworkHawkesProcesses</code> is to construct such impulse responses as mixture models. That is, for a family of (scaled) basis distribution functions, <span>$\phi_b: \{ 1, \dots, D \} \rightarrow [0, 1]$</span> for <span>$b = 1, \dots, B$</span>, the impulse response is defined as</p><p class="math-container">\[\hbar[d; \theta_{n \rightarrow n&#39;}] = \sum_{b=1}^B \theta_{n \rightarrow n&#39;}^{(b)} \cdot \phi_b[d] \\
\sum_{d=1}^D \phi_b[d] \cdot \Delta t = 1 \\
\sum_{b=1}^B \theta_{n \rightarrow n&#39;}^{(b)} = 1\]</p><p>The discretized Gaussian family of basis functions is the only family currently provided by <code>NetworkHawkesProcesses</code> via the <code>DiscreteGaussianImpulseResponse</code> type. It&#39;s members are defined by</p><p class="math-container">\[\phi_b[d] = \frac{\exp \{ -\frac{1}{2} \left( d - \mu_b \right)^2 \} }{\Delta t \cdot Z}\]</p><p>where <span>$\mu_b$</span> are evenly spaced on <span>$[1, D]$</span>, <span>$\sigma = \frac{D}{B - 1}$</span>, and <span>$Z$</span> is a normalization constant. An example of one such distribution is shown below.</p><p><img src="../assets/img/discrete-gaussian-impulse-response.svg" alt="Discrete Gaussian Impulse Response"/></p><section class="footnotes is-size-7"><ul><li class="footnote" id="footnote-1"><a class="tag is-link" href="#citeref-1">1</a>On the other hand, discrete-time processes offer lower resolution: they cannot capture &quot;instantaneous&quot; interactions between events. </li></ul></section></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../">« Home</a><a class="docs-footer-nextpage" href="../examples/">Examples »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.24 on <span class="colophon-date" title="Thursday 16 February 2023 04:02">Thursday 16 February 2023</span>. Using Julia version 1.8.5.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
